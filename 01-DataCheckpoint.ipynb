{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "    Noah Berger: Writing - original draft\n",
    "    Levi Bradley: Writing - original draft\n",
    "    Nicholas Nieto: Writing - original draft\n",
    "    Henry Ka: Writing - original draft\n",
    "    Dillon Lukaszewski: Writing - original draft\n",
    "\n",
    "\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Alice Anderson: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can the populatity of music ladden with excapist sentiments serve as an indicator twords the current economic environment of the US? Just as the 2008 recession had coincided with the rise of \"recession pop\" is there music with similar sentiment that is popular today, and if so is there data to show that the current economic climate of the US is not ideal?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music has been a cultural product and public pastime since as long as most of humanity can remember. And as such, music has been a driving force during times of struggle in many economic and social senses experiences among people across the world. As stated by Shanmugaboopathi, \"'music can influence the mind and emotions of people'. Almost all the people, about 92.16% of the respondents, have positively reacted and 5.88% of the participants have denied the statement.\"(Shanmugaboopathi, D., and J. Catoto, 2022).3 Shanmugaboopathi shows that music is heavily prevalent in how humans experience and interact with life on the psychological/emotional level. With additional notable examples of this being times of recession like the 1920s and even more recent such as the 2010s.\n",
    "\n",
    "During this era, music served as a key play into cultural life, desire for joy, and for pleasure. Especially energy and time dedicated to escapism and the experience. A topic in of itself can be observed from a technological streaming standpoint. Regardless, this has been researched. As de Lucio and their colleagues note, “Consumers postpone the purchase of durables, use more repair services, provide some services on their own and are most likely prone to pursuing pleasure consumption.” Which has been aptly described as the Lipstick Effect.”(de Lucio, J., Palomeque, M). The effect itself being something particularly unique to economic strife and can be seen in other economic sectors besides music but I digress.\n",
    "\n",
    "With music’s impact and the overall importance of economic growth and study. The two have been combined together into analysis. Marco Palomeque has taken care to be analytical in their approach. Recording such as music consumption and consumer constraint. Hoping to analyze and refine. Aiming to measure the positiveness of music coming out during the COVID-19 era. Including additional factors such as the economy and social factors,1 and how those 3 as a whole play into the overall social impacts of the lipstick effect. Even beyond that, Paleomeque’s research made sure to keep a thorough measure of unemployment tand its implication on the human psyche, iterating as “Unemployment has a negative impact on both well-being and mental health. During recessions, the latter is affected not only by unemployment, but by job insecurity, increased workload and changes in job scope”(palomeque.)\n",
    "\n",
    "Another Group adjusted, to focus on the billboards, magazines, and survey data related to songs during the recession. Using data banks such as North American Industry Classification System, databases from Dun and Bradstreet and more.4 Taking a look into deeper implications of music's success in the 2000s. Choosing to focus on some of the five most popular music cities and how the trend in music and economic downturn play together. Things such as employee counts and number of businesses in music related sectors were also analyzed. Especially when the music would touch upon rumination, something that differs from the general trend of desiring upbeat music during times of concern. The emphasis on \"pessimistic rumination\" makes for an interesting perspective.\n",
    "\n",
    "References + Citations\n",
    "\n",
    "    ^ de Lucio, J., Palomeque, M. Music preferences as an instrument of emotional self-regulation along the business cycle. J Cult Econ 47, 181–204 (2023). https://doi.org/10.1007/s10824-022-09454-7\n",
    "    ^ Palomeque, M., de-Lucio, J. The Soundtrack of a Crisis: More Positive Music Preferences During Economic and Social Adversity. J Happiness Stud 25, 44 (2024). https://doi.org/10.1007/s10902-024-00757-4\n",
    "    ^ Shanmugaboopathi, D., and J. Catoto. \"Evaluation of the influence of music on modern culture and society.\" Technoarete Transactions on Advances in Social Sciences and Humanities 2.4 (2022): 19-26.\n",
    "    ^ Taylor, Frederick J., and Phillip A. Terrell. \"An analysis of economic trends in US music industry capitals: 1995-2003, with implications for music industry education.\" MEIEA Journal 4.1 (2004): 105-135.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that there exisists some correlation between thre two while it may not be a strong connection, it most liekly does exist. When the circumstances for an unfavorable economy are present, it would more than likelty influence the people to seek out forms of media to provide a semblence of escape, thus even if things like GDP may show a continued upward growth, the popularity of escapist music may suggest that GDP alone may not serve as a definite measure of the economic climate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "\n",
    "Temp Data:\n",
    "\n",
    "### Dataset #1:\n",
    "- Name: Top 10000 Songs on Spotify 1950-Now\n",
    "- Link: https://www.kaggle.com/datasets/joebeachcapital/top-10000-spotify-songs-1960-now/data\n",
    "- Number of Observations: 10000\n",
    "- Number of variables: 35\n",
    "- Relevant Variables:\n",
    "    - Track Name: Name of the song\n",
    "    - Artist Name: Name of the people who made the song\n",
    "    - Year: The year the song was released\n",
    "    - Popularity: A score given to each song based on Spotify's popularity ranking\n",
    "    - Artist Genre: Genre of music the artist generally makes\n",
    "    - danceability: Spotify's metric to track how danceable the song is\n",
    "    - energy: Spotify's metric to track the intensity of a song\n",
    "    - loudness: Spotify's metric to track the loudness of a song\n",
    "    - speechiness: Spotify's metric to determine the presence of spoken words in a song. A low speechiness means that it's mostly just music.\n",
    "    - acousticness: Spotify's metric to determine if a song has more acoustics or electronics. A low value means it's more electronic\n",
    "    - instrumentalness: Spotify's metric to determine if a song is more instrumental\n",
    "    - valence: Spotify's metric to determine if a song is happy\n",
    "- Shortcomings: This data set does not contain the lyrics of the songs, nor does it contain the genre of the specific songs. Additionally, all of Spotify's metrics are kept secret by Spotify, so it is hard to verify their accuracy.\n",
    "\n",
    "### Dataset #2:\n",
    "- Name: Billboard Hot-100[2000-2023] data with features\n",
    "- Link: https://www.kaggle.com/datasets/suparnabiswas/billboard-hot-1002000-2023-data-with-features\n",
    "- Number of Observations: 3397\n",
    "- Number of variables: 26\n",
    "- Relevant Variables:\n",
    "    - Song: Name of the song\n",
    "    - band_singer: Name of the people who made the song\n",
    "    - year: The year the song was released\n",
    "    - lyrics: The lyrics of the song\n",
    "    - ranking: The ranking that the Billboard Hot-100 gave the song. A lower ranking means that it was more popualar of a song.\n",
    "    - danceability: Spotify's metric to track how danceable the song is\n",
    "    - energy: Spotify's metric to track the intensity of a song\n",
    "    - valence: Spotify's metric to determine if a song is happy\n",
    "    - tempo: The speed of a song in beats per minute\n",
    "    - loudness: Spotify's metric to track the loudness of a song\n",
    "    - speechiness: Spotify's metric to determine the presence of spoken words (not singing). A low speechiness means that it's mostly just music.\n",
    "    - acousticness: Spotify's metric to determine if a song has more acoustics or electronics. A low value means it's more electronic\n",
    "    - instrumentalness: Spotify's metric to determine if a song is more instrumental\n",
    "- Shortcomings: This data set only includes 100 songs per year, and it is deemed popular by the Billboard Hot 100, which changes qualifications from time to time. In addition to the first dataset, the metrics are mostly from Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://drive.google.com/uc?export=download&id=1EicbDzSKW_ghJcHym__ZFAzPk_KIhoX6', 'filename':'billboard_24years_lyrics_spotify.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?export=download&id=1s2nxVXyErICi92tLzKOzWl8WGYQ9uJxx', 'filename':'top_10000_1950-now.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2, style=\"white\")\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10000 Songs on Spotify 1950-Now\n",
    "\n",
    "This dataset includes a list of around 10000 songs that are popular on Spotify that released in the past 75 years. Additionally, it includes Spotify metadata such as popularity, danceability, energy, valence, loudness, speechiness, acousticness, and instrumentalness. All but the loudness and popularity are float values that range from 0 to 1, with 1 meaning that the song has a higher factor of the given variable. These values will help to determine if a song is more upbeat and joyful or slower and sadder. Additionally, Spotify gives each song a popularity score that helps their algorithm determine whether or not to recommend a song to the listener. This value ranges from 0, not a very popular song, to 100, a very popular song. This value will help us to determine the genres of music that have higher popularity by comparing them to the artist_genre values. Additionally, there is a tempo variable that is in beats per minute, which will help us to verify that some songs are edm, or similar genres of music. The main downside of this data set is that most of the data comes from values that Spotify gave each song, and the determination of each value is kept hidden by Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the dataset and get a basic ass look\n",
    "df_spotify = pd.read_csv(\"data/00-raw/top_10000_1950-now.csv\")\n",
    "df_spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing the data, it appears that the headers are case sensitive and have white space. Therefore, while removing unneccessary columns, I am also going to make the column names more standardized. Additionally, it appears that the release date gives the exact day for some values and just the year for others, so it would be better to remove the exact date and go by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep the relevant columns and fix the names\n",
    "df_spotify.columns = df_spotify.columns.str.lower().str.replace(' ', '_')\n",
    "columns_to_keep = ['track_name', 'artist_name(s)', 'album_release_date', 'popularity', 'artist_genres', 'danceability', 'energy', 'valence', 'tempo', 'loudness', 'speechiness', 'acousticness', 'instrumentalness']\n",
    "df_spotify_tidy = df_spotify[columns_to_keep]\n",
    "df_spotify_tidy = df_spotify_tidy.rename(columns = {'track_name' : 'song', 'artist_name(s)' : 'artist',\n",
    "                                                        'album_release_date' : 'year'})\n",
    "#This is to make it so that it shows just the year and not the full data\n",
    "df_spotify_tidy['year'] = df_spotify_tidy['year'].str[:4]\n",
    "#The following line will convert the year column into integers. Uncomment later if neccessary.\n",
    "#df_spotify_tidy['year'] = pd.to_numeric(df_spotify_tidy['year'], downcast='integer')\n",
    "\n",
    "df_spotify_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the size of the data\n",
    "#Look at the size of the data\n",
    "rows = df_spotify_tidy.shape[0]\n",
    "columns = df_spotify_tidy.shape[1]\n",
    "print(\"The number of rows is: \", rows)\n",
    "print(\"The number of columns is: \", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the number of nulls in each column\n",
    "missing_counts = df_spotify_tidy.isnull().sum()\n",
    "print(missing_counts)\n",
    "print('\\n')\n",
    "percent_missing = (df_spotify_tidy.isnull().sum() / len(df_spotify_tidy)) * 100\n",
    "print(percent_missing)\n",
    "print('\\n')\n",
    "null_rows = df_spotify_tidy.isnull().any(axis=1).sum()\n",
    "print(\"Number of rows with a null value: \", null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that this dataset does not contain many null values, which means that it should be fine to remove all rows that contain a null in the cleaning process. We will still have 95% of our observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Outliers\n",
    "#Everything here should be between 0 and 1\n",
    "sns.boxplot(data=df_spotify_tidy[['danceability', 'energy', 'valence', 'speechiness', 'acousticness', 'instrumentalness']])\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot here verifies that all the data fall within the values that they were supposed to so there is no incorrect data here. The main variables that appear to contain a lot of outliers are speechiness and instrumentalness. For speechiness, the outliers likely represent spoken word music such as rap and hip-hop while the outliers for instrumentalness will likely represent genres of music with close to no words, like edm. Acousticness also appears to have a good number of outliers, but that would most likely account for classical music or similar genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "#Removing duplicates\n",
    "df_spotify_clean = df_spotify_tidy.drop_duplicates(subset=['song','artist'], keep='first')\n",
    "df_spotify_clean = df_spotify_clean.dropna()\n",
    "rows = df_spotify_clean.shape[0]\n",
    "columns = df_spotify_clean.shape[1]\n",
    "print(\"The new number of rows is: \", rows)\n",
    "print(\"The new number of columns is: \", columns)\n",
    "df_spotify_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null values and any duplicate songs have been removed from the dataset, so everything should be clean and tidy now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Billboard-Hot 100 #2 \n",
    "\n",
    "This dataset is composed of all the songs that were put on the Billboard Hot 100 from 2000 to 2023. The main component that makes this dataset helpful compared to the top songs on Spotify dataset is that this one has columns for the rank received on the Billboard, with the year it was given the rank, and the music lyrics. The rank is a value from 1 to 100, where 1 means that the song was the most popular of that year and 100 was the least popular. This will help determine the songs that were more popular during economic crises. Additionally, we can use sentiment analysis on the lyrics to determine if the most popular songs during a year with an economic crisis had higher escapism values. This dataset also includes Spotify data, but after examining the null values, it appears that most of the values are null. This can be fixed later by using the Spotify metrics from the songs in dataset one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the dataset and get a basic ass look\n",
    "df_billboard = pd.read_csv(\"data/00-raw/billboard_24years_lyrics_spotify.csv\")\n",
    "df_billboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here appears to be fairly tidy, so we just need to rename any weird column names and remove any columns that are not important towards our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tidying up the data\n",
    "#Only keeping relevent columns and renaming weird ones\n",
    "columns_to_keep = ['song', 'band_singer', 'year', 'lyrics', 'ranking', 'danceability', 'energy', 'valence', 'tempo', 'loudness', 'speechiness', 'acousticness', 'instrumentalness']\n",
    "df_billboard_tidy = df_billboard[columns_to_keep]\n",
    "df_billboard_tidy = df_billboard_tidy.rename(columns = {'band_singer' : 'artist'})\n",
    "df_billboard_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the size of the data\n",
    "rows = df_billboard_tidy.shape[0]\n",
    "columns = df_billboard_tidy.shape[1]\n",
    "print(\"The number of rows is: \", rows)\n",
    "print(\"The number of columns is: \", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finding the number of nulls in each column\n",
    "missing_counts = df_billboard_tidy.isnull().sum()\n",
    "print(missing_counts)\n",
    "print('\\n')\n",
    "percent_missing = (df_billboard_tidy.isnull().sum() / len(df_billboard_tidy)) * 100\n",
    "print(percent_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves my observation that the null values are only in the columns that use Spotify data. Therefore, this dataset is primarily useful for the ranking system and the lyrics. We can leave the values null for right now, and in the future, if deemed necessary, we can merge this with the Spotify dataset to get the Spotify data for each of the songs on the Billboard. The only downside is that we may still not have a single dataset with all of the important variables if there is not enough overlap between the songs listed in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Outliers\n",
    "#The only important outliers here would be the word count\n",
    "df_billboard_tidy['word_count'] = df_billboard_tidy['lyrics'].astype(str).apply(lambda x: len(x.split()))\n",
    "sns.boxplot(data=df_billboard_tidy['word_count'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_billboard_tidy.sort_values('word_count', ascending=False)[['song', 'artist', 'word_count']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only important ouliers for this data are going to be in the lyrics column since we verrified that the other columns data are not neccessary for this dataset since the Spotify dataset contains the appropriate data. This boxplot shows us that the there are mainly outliers that have a higher than average word count. Most of the outliers can be written off as songs that simply have a lot of lyrics, like rap, or longer songs. However, there are some songs that have over 10000 words, which is most likely a data error, so we will remove them in the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "#Removing duplicates\n",
    "df_billboard_clean = df_billboard_tidy.drop_duplicates(subset=['year','ranking'], keep='first')\n",
    "df_billboard_clean = df_billboard_clean[df_billboard_clean['word_count'] < 5000]\n",
    "rows = df_billboard_clean.shape[0]\n",
    "columns = df_billboard_clean.shape[1]\n",
    "print(\"The new number of rows is: \", rows)\n",
    "print(\"The new number of columns is: \", columns)\n",
    "df_billboard_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stated why we previously did not remove null values, and after removing duplicate songs and unrealistically wordy songs, our dataset is now clean and tidy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [ ] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> As our research question involves a lot of data collection regarding popular pop songs, as a group we will be mindful of any potential biases that could be introducted during data collection, such as selection bias or sampling bias.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> While we do not intend on the exposure of any personally identifiable information, we will take this into consideration, avoiding the collection of any additional personal or private information that is not relevant to our analysis.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> Potential downstream bias will be considered, and we acknowledge that we must pay close attention to biased outcomes as we collect data.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> While we intend on using publicly available lyrics, we will ensure that we handle the data in a responsible manner.\n",
    "\n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> We do not expect long-term storage of our data to be necessary, and so intend on retaining the data only for the duration of our project.\n",
    "\n",
    "### C. Analysis\n",
    " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The datasets we intend on using will go through an appropriate process of data wrangling and cleaning to ensure that no possible source of bias goes unchecked.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We are committed to presenting representations in a manner which accurately reflects the underlying data.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We intend on using non-PII data which is publicly accessible. No personally identifiable information will be used beyond what is necessary for analysis.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> We will document our steps clearly so that our methods and decisions are reproducible.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> We acknowledge the risk of proxy discrimination and we will examine our variables to ensure that such proxy discrimination is not introduced.\n",
    "\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> We are aware that our choice of defining metrics can influence our conclusions, and we will consider additional metrics if we feel the need to do so.\n",
    "\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [ ] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will primarily use the group chat to communicate, and try to respond as soon as possible.\n",
    "* We will meet once a week on Wednesdays.\n",
    "* If there is a conflict of ideas, we go with a majority vote among the group.\n",
    "* kindness and/or basic human decency."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them\n",
    "\n",
    "**Week 1 - Proposal & Planning**:\n",
    "Finalize the research question and overall project scope. Assign preliminary roles within the group and confirm the types of datasets needed for the project. Our team will meet on Wednesday to align expectations and finalize the project proposal for submission.\n",
    "\n",
    "**Week 2 - Data Collection & Cleaning**:\n",
    "Begin collecting music-related data, including chart data, audio features, lyrics, and relevant economic indicators. Start cleaning and preprocessing the datasets. Meet on Wednesday to review data quality, address issues, and adjust the data collection plan if needed. \n",
    "\n",
    "**Week 3 - Exploratory Data Analysis (EDA)**:\n",
    "Conduct exploratory data analysis to identify initial trends and patterns in music features, lyrical sentiment, and economic variables. Use the Wednesday meeting to discuss preliminary findings and refine the analysis approach.\n",
    "\n",
    "**Week 4 - Analysis & Modeling**:\n",
    "Perform statistical analyses and comparisons to evaluate the research question. Explore relationships between music trends and economic conditions. During the Wednesday meeting, review results and decide on any additional analyses needed.\n",
    "\n",
    "**Week 5 - Interpretation & Drafting Results**:\n",
    "Interpret analysis results and begin drafting visualizations, results, and discussion sections. Use the Wednesday meeting to review interpretations, ensure clarity, and check alignment with the original research question.\n",
    "\n",
    "**Week 6 - Finalization & Presentation (Final Video)**:\n",
    "Finalize all analyses, visualizations, and written components of the project. Prepare the final report and presentation materials. Use the Wednesday meeting to polish the final deliverables and make any last revisions before submission.\n",
    "\n",
    "---\n",
    "\n",
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
    "|--------------|--------------|--------------------------|--------------------|\n",
    "| 2/4 | 1:30pm | Align on course expectations, project goals, and team workflow; review proposed music–economy research ideas; explore potential datasets (Spotify, Billboard, FRED) | Finalize research question; agree on scope (time span, music features, economic indicators); confirm proposal direction |\n",
    "| Week 2 | Wednesday | Download and inspect Spotify and Billboard datasets; collect GDP and unemployment data from FRED; begin basic data cleaning | Review data quality and availability; discuss ethical considerations; finalize which datasets will be used |\n",
    "| Week 3 | Wednesday | Perform exploratory data analysis (EDA) on music features, genres, and lyrics; align music data with economic indicators by year | Discuss EDA results; identify key trends and variables; refine analysis plan |\n",
    "| Week 4 | Wednesday | Conduct statistical analyses examining relationships between music trends (genre, sentiment, popularity) and economic conditions | Review analysis outcomes; interpret findings; decide on additional analyses if needed |\n",
    "| Week 5 | Wednesday | Create visualizations; draft results and discussion sections connecting music trends to economic indicators | Review clarity and coherence of results; ensure alignment with research question and hypothesis |\n",
    "| Week 6 | Wednesday | Finalize analyses, figures, and written components of the project | Polish final report and presentation; make final revisions before submission |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
